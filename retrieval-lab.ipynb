{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "dcsylqc6hs5hqndpfgpn",
   "authorId": "1268462853256",
   "authorName": "DSCHULER36",
   "authorEmail": "dschuler36@gmail.com",
   "sessionId": "5d6c93e1-4a26-41b6-9bd0-f1b48ef84eac",
   "lastEditTime": 1747315586505
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02c0edb-d8af-448e-94e9-17367d84e55d",
   "metadata": {
    "name": "Overview",
    "collapsed": false
   },
   "source": "# Retrieval Hands On Lab\n\n## Objectives\nBy the end of this lab, participants will:\n\n1. Understand how to parse PDFs inside Snowflake\n2. Understand how to create vector representations of text data and load it into Snowflake tables\n3. Perform similarity search against embeddings in Snowflake\n4. Use Snowflake Cortex Search for retrieval and understand the benefits compared to simple similarity search"
  },
  {
   "cell_type": "markdown",
   "id": "f065f51a-a7a7-4a0d-a686-208956c9639e",
   "metadata": {
    "name": "Part_1",
    "collapsed": false
   },
   "source": "# Part 1: Setup\nIn this section, we will:\n\n1. Create some snowflake objects to store our data in\n2. Upload a PDF of Cincinnati Parks' 3 year development plan into a stage\n3. Parse the PDF into usable text and load the results into a Snowflake table"
  },
  {
   "cell_type": "code",
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "sql",
    "name": "Create_Snowflake_Objects"
   },
   "source": "CREATE OR REPLACE DATABASE RETRIEVAL_LAB;\nCREATE OR REPLACE SCHEMA DATA;\nUSE RETRIEVAL_LAB.DATA;\nCREATE OR REPLACE STAGE docs ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE') DIRECTORY = ( ENABLE = true );",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "a1b645d3-13e9-4be9-8bee-7622479929a3",
   "metadata": {
    "name": "PDF_Upload_Instructions",
    "collapsed": false
   },
   "source": "Here is where we will upload the PDF. To do so, navigate to our newly created stage by:\n\n1. Click on the Database icon on the left nav bar\n2. Go to your 'RETRIEVAL_LAB' database\n3. Expand the 'DATA' schema\n4. Click on 'Stages'\n5. Click on the 'DOCS' stage\n\nOnce you're at the stage, we will download and upload the pdf.\n\nTODO: Hoping we can just store the pdf in one spot"
  },
  {
   "cell_type": "code",
   "id": "c695373e-ac74-4b62-a1f1-08206cbd5c81",
   "metadata": {
    "language": "sql",
    "name": "View_PDF",
    "codeCollapsed": false
   },
   "source": "-- Open the URL generated below\nSELECT GET_PRESIGNED_URL('@docs', 'cincinnati-parks-3-year-plan.pdf', 3600);",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "ec8ac735-69a5-4b52-980b-d16b6369a833",
   "metadata": {
    "language": "sql",
    "name": "Create_Parsed_PDF_Table",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- This table will store the text from the parsed PDF\nCREATE OR REPLACE TABLE PARSED_PDFS ( \n    RELATIVE_PATH VARCHAR,\n    SIZE NUMBER(38,0),\n    FILE_URL VARCHAR,\n    PARSED_DATA VARCHAR);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d4433273-b96e-460b-bf04-706a4d5e0661",
   "metadata": {
    "language": "sql",
    "name": "Parse_PDFs",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- We use Snowflake Cortex's PARSE_DOCUMENT function to extract the text from the pdf and save it to a column\nINSERT INTO PARSED_PDFS (relative_path, size, file_url, parsed_data)\nSELECT \n        relative_path,\n        size,\n        file_url,\n    SNOWFLAKE.CORTEX.PARSE_DOCUMENT('@docs', relative_path, { 'mode': 'OCR' }):content AS parsed_data\n    FROM directory(@docs);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ee574655-7368-41c8-8fcb-eaaeae3ceff0",
   "metadata": {
    "language": "sql",
    "name": "Verify_PDF_Parsing",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Verify the data was successfully parsed\nselect * from PARSED_PDFS;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "4be61e87-16c1-4406-9209-321a1d2363c9",
   "metadata": {
    "name": "Part2",
    "collapsed": false
   },
   "source": "## Part 2 - Generate Embeddings\n\nIn this section, we will:\n\n1. Explore various strategies for chunking the text data\n2. Generate embeddings for our text chunks\n3. Load the results into a Snowflake table using the `VECTOR` datatype"
  },
  {
   "cell_type": "markdown",
   "id": "4a36ab18-e357-41e5-995e-52b2a79f4d30",
   "metadata": {
    "name": "cell1",
    "collapsed": false
   },
   "source": "### Chunking Strategies\n\nIn this section, we'll explore various chunking strategies. The right strategy will ultimately depend on the data and use case at hand. In our example, the PDF is cleanly delineated into paragraphs, so a simple regex based chunker is ideal.\n\n1. Snowflake Recursive Text Splitter\n2. Semantic Chunking\n3. Simple Chunking"
  },
  {
   "cell_type": "code",
   "id": "ef3d7283-ccd9-4c5d-a2d0-4326aef5708c",
   "metadata": {
    "language": "sql",
    "name": "Snowflake_Recursive_Chunker"
   },
   "outputs": [],
   "source": "SELECT\n  f.value::string AS chunk\nFROM\n  PARSED_PDFS,\n  LATERAL FLATTEN(\n    INPUT => SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER(\n      PARSED_DATA,\n      'none',\n      1000,\n      100\n    )\n  ) f;",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "1deb0a49-5ca6-4567-bac6-d3d5dd2109d1",
   "metadata": {
    "language": "python",
    "name": "Read_Parsed_PDF_Table_In_Python",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.core import Root\n\nsession = get_active_session()\n\nparsed_data_df = session.table('parsed_pdfs')\nparsed_text = parsed_data_df.collect()[0]\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "88a37a78-3109-4231-ba66-3d7a27111a76",
   "metadata": {
    "language": "python",
    "name": "Simple_Chunking",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import re\n\ndef chunk_by_project(parsed_text):\n    # Use regex to find titles and their following paragraphs\n    # A project title is in all caps and followed by a paragraph (could be multiline\")\n    pattern = r'([A-Z0-9 ,&\\-()]+)\\n(.*?)(?=(?:\\n[A-Z0-9 ,&\\-()]+\\n)|\\Z)'  # \\Z means end of string\n    matches = re.findall(pattern, parsed_text['PARSED_DATA'], re.DOTALL)\n\n    chunk_records = []\n    for title, description in matches:\n        clean_title = title.strip()\n        clean_description = description.strip().replace('\\n', ' ')\n        text_chunk = f\"{clean_title}\\n{clean_description}\"\n        chunk_records.append({\n            \"relative_path\": parsed_text[\"RELATIVE_PATH\"],\n            \"size\": parsed_text[\"SIZE\"],\n            \"file_url\": parsed_text[\"FILE_URL\"],\n            \"chunk\": text_chunk\n        })\n    return chunk_records\n    \n\nchunks = chunk_by_project(parsed_text)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "80620465-147e-42a5-9a46-5be0db654b5f",
   "metadata": {
    "language": "python",
    "name": "View_Chunk_Results",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "for chunk in chunks:\n    print(chunk)",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e6172931-178e-4170-878d-53eb03e43b2a",
   "metadata": {
    "language": "python",
    "name": "Generate_Embeddings",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.cortex import embed_text_768\n\nmodel = 'e5-base-v2'\nfor chunk in chunks:\n    chunk['embedding'] = embed_text_768(model, chunk['chunk'], session)\n    ",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "c209153f-9804-4dc1-9d79-4b37ff093a8d",
   "metadata": {
    "language": "python",
    "name": "Load_Embeddings",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark.types import VectorType, DoubleType\ndf = session.create_dataframe(chunks)\ndf = df.with_column('embedding', df.col('embedding').cast(VectorType(float, 768)))\ndf.write.save_as_table(\"DOCS_CHUNKS_TABLE\")",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ef7e4a58-2caa-48a3-8968-dd8981b244c4",
   "metadata": {
    "language": "sql",
    "name": "Verify_Embeddings",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "select * from DOCS_CHUNKS_TABLE;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "95b337bb-6f95-43db-b26f-733c98a3f6a3",
   "metadata": {
    "name": "Part_3",
    "collapsed": false
   },
   "source": "## Part 3: Test out different search methods\n\nIn this section, we will:\n\n1. Perform a standard cosine similarity search\n2. Create a Cortex Search Service\n3. Perform a search against the Cortex Search Service"
  },
  {
   "cell_type": "code",
   "id": "7e0f0842-88e2-468f-867d-d5726955776f",
   "metadata": {
    "language": "sql",
    "name": "cell13",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "select * from docs_chunks_table where contains(chunk, 'SAWYER POINT PLAYGROUND');",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "612e1a83-ddd1-47b9-aae2-08d6648c8c3a",
   "metadata": {
    "language": "sql",
    "name": "Standard_Vector_Search",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "-- Ault Park Trail\nSELECT VECTOR_COSINE_SIMILARITY(\n            docs_chunks_table.embedding,\n            SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2', 'When will the Ault Park trail plan complete?')\n       ) as similarity,\n       chunk\nFROM docs_chunks_table\nORDER BY similarity desc\nLIMIT 3\n;",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3536db19-0dcd-4a84-bee5-19740d7847bd",
   "metadata": {
    "name": "cell5",
    "collapsed": false
   },
   "source": "## Create Cortex Search Service for advanced hybrid search"
  },
  {
   "cell_type": "code",
   "id": "84a54785-f0e9-48cc-8b87-bde2476a0960",
   "metadata": {
    "language": "sql",
    "name": "Create_Cortex_Search_Service",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "CREATE OR REPLACE CORTEX SEARCH SERVICE parks_search_service\n  ON CHUNK\n  WAREHOUSE = compute_wh\n  TARGET_LAG = '1 day'\n  EMBEDDING_MODEL = 'snowflake-arctic-embed-m-v1.5'\n  AS (\n    SELECT\n        CHUNK,\n    FROM docs_chunks_table\n);",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e9276996-bca5-4498-9229-cf6739802f21",
   "metadata": {
    "language": "python",
    "name": "Cortex_Search_Results",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.core import Root\n\nsession = get_active_session()\n\nroot = Root(session)\nparks_search_service = (root\n  .databases[\"RETRIEVAL_LAB\"]\n  .schemas[\"DATA\"]\n  .cortex_search_services[\"parks_search_service\"]\n)\n\nresp = parks_search_service.search(\n  query=\"When will the Ault Park trail plan complete?\",\n  columns=[\"chunk\"],\n  limit=3\n)\n\nresults = json.loads(resp.to_json())['results']\n\nfor idx, chunk in enumerate(results):\n    print(f'Result: {idx+1}')\n    print(chunk['chunk'])",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "82843258-5703-4c77-a76e-2be53470c09b",
   "metadata": {
    "name": "Part_4",
    "collapsed": false
   },
   "source": "## Part 4: Evals\n\nIn this section, we will:\n\n1. Build out a sample of questions and ground truth results\n2. Create a framework for running our samples through both standard search and Cortex search\n3. Perform the evaluation and display the results"
  },
  {
   "cell_type": "code",
   "id": "d6d196d1-b06d-4031-a876-3fd0cb692882",
   "metadata": {
    "language": "python",
    "name": "Create_Eval_Set"
   },
   "outputs": [],
   "source": "eval_set = [\n    {\n        \"query\": \"When will the Ault Park trail plan complete?\",\n        \"expected_chunk\": \"AULT PARK VALLEY TRAIL One of the busiest trails in Cincinnati Parks is experiencing serious erosion issues along the creek also housing important sewer infrastructure. This project shores up the trail to keep hikers safe in advance of a larger MSD sewer project in the coming years to protect the trail in the long term. The project is underway and will close out in early 2025.\"\n    }\n]",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a0b4707b-c54b-41f1-9541-4176eaa6e4b2",
   "metadata": {
    "language": "python",
    "name": "Eval_Setup",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "from snowflake.snowpark import Session\nfrom snowflake.snowpark.functions import col\nimport json\n\nsession = Session.builder.getOrCreate()\n\n# Embed a text\ndef get_embedding(text):\n    result = session.sql(f\"SELECT SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2', '{text}') AS emb\").collect()[0]\n    return result['EMB']\n\n# Compute similarity between two texts\ndef compute_similarity(text1, text2):\n    result = session.sql(f\"\"\"\n        SELECT VECTOR_COSINE_SIMILARITY(\n            SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2', '{text1}'),\n            SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2', '{text2}')\n        ) AS sim\n    \"\"\").collect()[0]\n    return result[\"SIM\"]\n\n# Vector search - returns top result\ndef vector_search(query, k=3):\n    return session.sql(f\"\"\"\n        SELECT chunk, VECTOR_COSINE_SIMILARITY(\n            docs_chunks_table.embedding,\n            SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2', '{query}')\n        ) AS similarity\n        FROM docs_chunks_table\n        ORDER BY similarity DESC\n        LIMIT {k}\n    \"\"\").collect()\n\n# Cortex search\ndef cortex_search(query, limit=3):\n    parks_search_service = (root.databases[\"RETRIEVAL_LAB\"]\n                                    .schemas[\"DATA\"]\n                                    .cortex_search_services[\"parks_search_service\"])\n    resp = parks_search_service.search(\n        query=query,\n        columns=[\"chunk\"],\n        limit=limit\n    )\n    results = json.loads(resp.to_json())['results']\n    return results\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8ad6ead9-7089-4d4c-b0cd-7be833fe549e",
   "metadata": {
    "language": "python",
    "name": "cell2",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "results = []\n\nfor item in eval_set:\n    query = item['query']\n    expected = item['expected_chunk']\n\n    # Standard Vector Search\n    vector_results = vector_search(query, k=3)\n    vector_top1 = vector_results[0]['CHUNK']\n    vector_match_rank = next(\n        (i + 1 for i, r in enumerate(vector_results) if compute_similarity(r['CHUNK'], expected) > 0.9),\n        None\n    )\n    vector_top1_sim = compute_similarity(vector_top1, expected)\n\n    # Cortex Search\n    cortex_results = cortex_search(query, limit=3)\n    cortex_top1 = cortex_results[0]['chunk']\n    cortex_match_rank = next(\n        (i + 1 for i, r in enumerate(cortex_results) if compute_similarity(r['chunk'], expected) > 0.9),\n        None\n    )\n    cortex_top1_sim = compute_similarity(cortex_top1, expected)\n\n    results.append({\n        \"query\": query,\n        \"vector_top1_similarity\": round(vector_top1_sim, 3),\n        \"vector_hit_in_top3\": vector_match_rank is not None,\n        \"vector_hit_rank\": vector_match_rank if vector_match_rank else \"Miss\",\n        \"cortex_top1_similarity\": round(cortex_top1_sim, 3),\n        \"cortex_hit_in_top3\": cortex_match_rank is not None,\n        \"cortex_hit_rank\": cortex_match_rank if cortex_match_rank else \"Miss\"\n    })\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "22ddf8ec-7169-45bd-8a4a-5f1d98b150a1",
   "metadata": {
    "language": "python",
    "name": "cell3",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import pandas as pd\npd.DataFrame(results)\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5cae364e-5074-4396-b77b-fcf05ddd5422",
   "metadata": {
    "language": "python",
    "name": "cell4",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "",
   "execution_count": null
  }
 ]
}