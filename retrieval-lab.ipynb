{
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "notebookId": "ns22ir2pebtpjbv4m6ui",
   "authorId": "2986287304867",
   "authorName": "DSCHULER",
   "authorEmail": "dschuler@gaig.com",
   "sessionId": "2f7f78ed-f5dd-4a4d-a6ff-5a422b06f9c2",
   "lastEditTime": 1749317267245
  }
 },
 "nbformat_minor": 5,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f02c0edb-d8af-448e-94e9-17367d84e55d",
   "metadata": {
    "collapsed": false,
    "name": "Overview"
   },
   "source": [
    "# Retrieval Hands On Lab\n",
    "\n",
    "## Objectives\n",
    "By the end of this lab, participants will:\n",
    "\n",
    "1. Understand how to parse PDFs inside Snowflake\n",
    "2. Understand how to create vector representations of text data and load it into Snowflake tables\n",
    "3. Perform similarity search against embeddings in Snowflake\n",
    "4. Use Snowflake Cortex Search for retrieval and understand the benefits compared to simple similarity search\n",
    "5. Understand how to evaluate retrieval performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f065f51a-a7a7-4a0d-a686-208956c9639e",
   "metadata": {
    "collapsed": false,
    "name": "Part_1"
   },
   "source": [
    "# Part 1: Setup\n",
    "In this section, we will:\n",
    "\n",
    "1. Create some snowflake objects to store our data in\n",
    "2. Upload a PDF of Cincinnati Parks' 3 year development plan into a stage\n",
    "3. Parse the PDF into usable text and load the results into a Snowflake table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7397eb24-3ccf-4c42-ae1b-a9f797a98758",
   "metadata": {
    "collapsed": false,
    "name": "Inspect_PDF"
   },
   "source": [
    "## Inspect the PDF\n",
    "\n",
    "Download the Cincinnati Parks 3 year plan by clicking on the data directory, then clicking the '...' next to the PDF and choosing 'Download'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775908f-ca36-4846-8f38-5adca39217f2",
   "metadata": {
    "language": "sql",
    "name": "Create_Snowflake_Objects"
   },
   "outputs": [],
   "source": [
    "USE RETRIEVAL_LAB.PUBLIC;\n",
    "\n",
    "-- Create a stage to store our PDF\n",
    "CREATE OR REPLACE STAGE docs ENCRYPTION = (TYPE = 'SNOWFLAKE_SSE') DIRECTORY = ( ENABLE = true );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51d9541-9e4a-4446-a604-3dd5ef5d3969",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "Put_PDF_In_Stage"
   },
   "outputs": [],
   "source": [
    "from snowflake.snowpark.context import get_active_session\n",
    "from snowflake.core import Root\n",
    "\n",
    "session = get_active_session()\n",
    "pdf_path = \"./data/cincinnati-parks-3-year-plan.pdf\"\n",
    "\n",
    "session.file.put(\n",
    "    pdf_path,\n",
    "    \"@docs\",\n",
    "    auto_compress=False,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# Force a refresh on the stage so the doc is accessible\n",
    "session.sql(\"ALTER STAGE docs REFRESH\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500453d9-a3f9-4e93-93dc-88f6b16df299",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "Validate_File_In_Stage"
   },
   "outputs": [],
   "source": [
    "-- Verify PDF was properly uploaded\n",
    "LIST @docs;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8ac735-69a5-4b52-980b-d16b6369a833",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "Create_Parsed_PDF_Table"
   },
   "outputs": [],
   "source": [
    "-- This table will store the text from the parsed PDF\n",
    "CREATE OR REPLACE TABLE PARSED_PDFS ( \n",
    "    RELATIVE_PATH VARCHAR,\n",
    "    SIZE NUMBER(38,0),\n",
    "    FILE_URL VARCHAR,\n",
    "    PARSED_DATA VARCHAR);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4433273-b96e-460b-bf04-706a4d5e0661",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "Parse_PDFs"
   },
   "outputs": [],
   "source": [
    "-- We use Snowflake Cortex's PARSE_DOCUMENT function to extract the text from the pdf and save it to a column\n",
    "INSERT INTO PARSED_PDFS (relative_path, size, file_url, parsed_data)\n",
    "SELECT \n",
    "        relative_path,\n",
    "        size,\n",
    "        file_url,\n",
    "    SNOWFLAKE.CORTEX.PARSE_DOCUMENT('@docs', relative_path, { 'mode': 'OCR' }):content AS parsed_data\n",
    "    FROM directory(@docs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee574655-7368-41c8-8fcb-eaaeae3ceff0",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "Verify_PDF_Parsing"
   },
   "outputs": [],
   "source": [
    "-- Verify the data was successfully parsed\n",
    "select * from PARSED_PDFS;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be61e87-16c1-4406-9209-321a1d2363c9",
   "metadata": {
    "collapsed": false,
    "name": "Part2"
   },
   "source": [
    "## Part 2 - Generate Embeddings\n",
    "\n",
    "In this section, we will:\n",
    "\n",
    "1. Explore various strategies for chunking the text data\n",
    "2. Generate embeddings for our text chunks\n",
    "3. Load the results into a Snowflake table using the `VECTOR` datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a36ab18-e357-41e5-995e-52b2a79f4d30",
   "metadata": {
    "collapsed": false,
    "name": "Chunking_Strategies"
   },
   "source": "### Chunking Strategies\n\nIn this section, we'll explore various chunking strategies. The right strategy will ultimately depend on the data and use case at hand. The three strategies explored in this section are:\n\n1. **Snowflake's Recursive Text Splitter** - this method uses a set of separators to iteratively split the text. If the result of the split for the primary separator doesn't result in the desired chunk size, another pass will be taken through the text with the next separator. Snowflake's default separator list is `[”\\n\\n”, “\\n”, “ “, “”]`, meaning it will first use a paragraph break, then a line break, then a space, and then an empty string. This can be altered as needed.\n\n2. **Semantic Chunking** - this strategy attempts to generate chunks by accounting for the semantic meaning of text within the document. The goal is to create chunks comprised of sentences that cover the same theme or topic. This will result in more varied chunk sizes as opposed to always creating a chunk size of 500 tokens, as an example.\n\n3. **Paragraph Chunking** - this is a simpler strategy that can be used on documents that are well structured into paragraphs. In our case, this strategy makes a lot of sense as it will group each park plan into its own chunk."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd35ad8-6208-4cfd-ac5a-d11573d12626",
   "metadata": {
    "language": "python",
    "name": "Snowflake_Recursive_Chunker"
   },
   "outputs": [],
   "source": [
    "chunking_sql = \"\"\"\n",
    "    SELECT f.value::string AS chunk\n",
    "    FROM PARSED_PDFS,\n",
    "    LATERAL FLATTEN(\n",
    "      INPUT => SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER(\n",
    "      PARSED_DATA, -- column to split\n",
    "      'none', -- format ('none' or 'markdown')\n",
    "      1000, -- chunk size\n",
    "      100 -- overlap\n",
    "      )\n",
    "    ) f\n",
    "\"\"\"\n",
    "\n",
    "recursive_chunks = [row[\"CHUNK\"] for row in session.sql(chunking_sql).collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4905dc98-c538-47a8-97da-3eb4f5ab8d32",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "Semantic_Chunking"
   },
   "outputs": [],
   "source": "import re\nfrom typing import List\nfrom langchain.embeddings.base import Embeddings\nfrom langchain_experimental.text_splitter import SemanticChunker\nfrom snowflake.cortex import embed_text_768\n\n\n# Creating a custom Langchain Embeddings class for Snowflake to use with the SemanticChunker\nclass SnowflakeCortexEmbeddings(Embeddings):\n    def __init__(self):\n        self.model = 'e5-base-v2'\n\n    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n        results = []\n        for text in texts:\n            embedding = embed_text_768(self.model, text, session)\n            results.append(embedding)\n        return results\n\n    def embed_query(self, text: str) -> List[float]:\n        return self.embed_documents([text])[0]\n\n\nsnowflake_embeddings = SnowflakeCortexEmbeddings()\nchunker = SemanticChunker(embeddings=snowflake_embeddings)\n\nparsed_data_df = session.table('parsed_pdfs')\nparsed_text = parsed_data_df.collect()[0]\n\n# Removing line breaks to pass in a continuous string to the chunker\ncleaned_text = re.sub(r'\\n(?=\\S)', ' ', parsed_text[\"PARSED_DATA\"])\n\nchunks = chunker.create_documents([cleaned_text])\nsemantic_chunks = [doc.page_content for doc in chunks]\n            "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301e3bf7-b2dc-4798-970f-cf5e9b067b9b",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "Paragraph_Chunking"
   },
   "outputs": [],
   "source": "from snowflake.snowpark.context import get_active_session\nfrom snowflake.core import Root\n\ndef is_title(line):\n    stripped = line.strip()\n    return (\n        bool(stripped) and \n        stripped == stripped.upper() and \n        any(c.isalpha() for c in stripped)\n    )\n# Create chunks for each park and its project plan\ndef chunk_by_project(parsed_text):\n    lines = parsed_text[\"PARSED_DATA\"].splitlines()\n    chunks = []\n    current_title = None\n    current_desc_lines = []\n    i = 0\n    while i < len(lines):\n        line = lines[i].strip()\n        if is_title(line):\n            # Check if the next line is also a title (part of same heading)\n            title_lines = [line]\n            while i + 1 < len(lines) and is_title(lines[i + 1].strip()):\n                i += 1\n                title_lines.append(lines[i].strip())\n            # If we already have a title and description, save that chunk\n            if current_title:\n                chunk = f\"{current_title}\\n{' '.join(current_desc_lines).strip()}\"\n                chunks.append({\n                    \"relative_path\": parsed_text[\"RELATIVE_PATH\"],\n                    \"size\": parsed_text[\"SIZE\"],\n                    \"file_url\": parsed_text[\"FILE_URL\"],\n                    \"chunk\": chunk\n                })\n            # Start a new chunk\n            current_title = ' '.join(title_lines)\n            current_desc_lines = []\n        else:\n            current_desc_lines.append(line)\n        i += 1\n\n    # Add the last chunk\n    if current_title and current_desc_lines:\n        chunk = f\"{current_title}\\n{' '.join(current_desc_lines).strip()}\"\n        chunks.append({\n            \"relative_path\": parsed_text[\"RELATIVE_PATH\"],\n            \"size\": parsed_text[\"SIZE\"],\n            \"file_url\": parsed_text[\"FILE_URL\"],\n            \"chunk\": chunk\n        })\n\n    return chunks\n\nparagraph_chunks = chunk_by_project(parsed_text)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e07375-caee-4dbe-9255-6daa5f43921d",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "Compare_Chunking_Results"
   },
   "outputs": [],
   "source": "import pandas as pd\n\n\ndef count_tokens(text: str) -> int:\n    # This runs a SQL query to tokenize the text and count tokens\n    result = session.sql(f\"\"\"\n        SELECT SNOWFLAKE.CORTEX.COUNT_TOKENS('e5-base-v2', $${text}$$) AS token_count\n    \"\"\").collect()\n    return result[0][\"TOKEN_COUNT\"]\n\ndef get_summary_statistics(chunks, label):\n    token_counts = [count_tokens(chunk if isinstance(chunk, str) else chunk[\"chunk\"]) for chunk in chunks]\n    return {\n        \"strategy\": label,\n        \"num_chunks\": len(chunks),\n        \"min_tokens\": min(token_counts),\n        \"max_tokens\": max(token_counts),\n        \"avg_tokens\": sum(token_counts) / len(token_counts) if chunks else 0,\n    }\n\nall_summaries = [\n    get_summary_statistics(recursive_chunks, \"recursive\"),\n    get_summary_statistics(semantic_chunks, \"semantic\"),\n    get_summary_statistics(paragraph_chunks, \"paragraph\")\n]\n\nsummary_df = pd.DataFrame(all_summaries)\nsummary_df"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80620465-147e-42a5-9a46-5be0db654b5f",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "View_Chunk_Results"
   },
   "outputs": [],
   "source": [
    "# View paragraph chunks\n",
    "for idx, chunk in enumerate(paragraph_chunks):\n",
    "    if idx < 10:\n",
    "        print(f'chunk {idx}:', chunk['chunk'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6172931-178e-4170-878d-53eb03e43b2a",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "Generate_Embeddings"
   },
   "outputs": [],
   "source": "from snowflake.cortex import embed_text_768\n\n# Create embeddings for each chunk\nmodel = 'e5-base-v2'\nfor chunk in paragraph_chunks:\n    chunk['embedding'] = embed_text_768(model, chunk['chunk'], session)\n    "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c209153f-9804-4dc1-9d79-4b37ff093a8d",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "Load_Embeddings"
   },
   "outputs": [],
   "source": "from snowflake.snowpark.types import VectorType, DoubleType\n\n# Save off chunks and embeddings into new table\ndf = session.create_dataframe(paragraph_chunks)\ndf = df.with_column('embedding', df.col('embedding').cast(VectorType(float, 768)))\ndf.write.save_as_table(\"DOCS_CHUNKS_TABLE\", mode='overwrite')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7e4a58-2caa-48a3-8968-dd8981b244c4",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "Verify_Embeddings"
   },
   "outputs": [],
   "source": "-- Validate table\nselect chunk, embedding \nfrom DOCS_CHUNKS_TABLE\nlimit 10;"
  },
  {
   "cell_type": "markdown",
   "id": "95b337bb-6f95-43db-b26f-733c98a3f6a3",
   "metadata": {
    "collapsed": false,
    "name": "Part_3"
   },
   "source": [
    "## Part 3: Test out different search methods\n",
    "\n",
    "In this section, we will:\n",
    "\n",
    "1. Perform a standard cosine similarity search\n",
    "2. Create a Cortex Search Service\n",
    "3. Perform a search against the Cortex Search Service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2451524-1339-46d0-bc9b-e2bfb37bb5b8",
   "metadata": {
    "collapsed": false,
    "name": "Standard_Search_Desc"
   },
   "source": "### Standard Similarity Search\nSnowflake offers a built in function to perform semantic similarity search. You provide the column of type `VECTOR` that you will be searching and the embedding of your search query. It will return the similarity score (between -1 and 1) for each embedding in your vector column.\n\nOne thing to note is that when inserting data into a column of type `VECTOR`, Snowflake does not create an Approximate Nearest Neighbor (ANN) index like you would get with many Vector databases. This will result in slower retrieval speed."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "612e1a83-ddd1-47b9-aae2-08d6648c8c3a",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "Standard_Vector_Search"
   },
   "outputs": [],
   "source": "-- Ault Park Trail\nSELECT VECTOR_COSINE_SIMILARITY(\n            docs_chunks_table.embedding,\n            SNOWFLAKE.CORTEX.EMBED_TEXT_768('e5-base-v2', 'When will the Ault Park trail plan complete?')\n       ) as similarity,\n       chunk\nFROM docs_chunks_table\nORDER BY similarity desc\nLIMIT 10\n;"
  },
  {
   "cell_type": "markdown",
   "id": "bc84a433-8a02-40c8-9ea2-42430f043474",
   "metadata": {
    "collapsed": false,
    "name": "Cortex_Search_Desc"
   },
   "source": "### Snowflake Cortex Search Service\n\nThe Cortex Search Service provides a simple way to perform search against your data. It handles embedding data, loading it into a table, and provides a low-latency interface for searching. The search method is a hybrid of keyword and vector search and also has a built-in semantic reranker to provide the most relevant chunks of data.\n\nAll of this together provides a simple mechanism for high quality, performant search inside Snowflake. Given the speed increase when compared to standard cosine similarity search, Snowflake is likely creating an ANN index for Cortex Search, although it is not explicitly called out in the docs."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a54785-f0e9-48cc-8b87-bde2476a0960",
   "metadata": {
    "codeCollapsed": false,
    "language": "sql",
    "name": "Create_Cortex_Search_Service"
   },
   "outputs": [],
   "source": "CREATE OR REPLACE CORTEX SEARCH SERVICE parks_search_service\n  ON CHUNK\n  WAREHOUSE = compute_wh\n  TARGET_LAG = '1 day'\n  EMBEDDING_MODEL = 'snowflake-arctic-embed-m-v1.5'\n  AS (\n    SELECT\n        CHUNK,\n    FROM docs_chunks_table\n);"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9276996-bca5-4498-9229-cf6739802f21",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "Cortex_Search_Results"
   },
   "outputs": [],
   "source": "# Quick test of the search service\nimport json\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.core import Root\n\nroot = Root(session)\nparks_search_service = (root\n  .databases[\"RETRIEVAL_LAB\"]\n  .schemas[\"PUBLIC\"]\n  .cortex_search_services[\"parks_search_service\"]\n)\n\nresp = parks_search_service.search(\n  query=\"When will the Ault Park trail plan complete?\",\n  columns=[\"chunk\"],\n  limit=3\n)\n\nresults = json.loads(resp.to_json())['results']\n\nfor idx, chunk in enumerate(results):\n    print(f'Result: {idx+1}')\n    print(chunk['chunk'])"
  },
  {
   "cell_type": "markdown",
   "id": "82843258-5703-4c77-a76e-2be53470c09b",
   "metadata": {
    "collapsed": false,
    "name": "Part_4"
   },
   "source": [
    "## Part 4: Evals\n",
    "\n",
    "In this section, we'll:\n",
    "\n",
    "1. Build out a sample of questions and ground truth results\n",
    "2. Create a framework for running our samples through both standard search and Cortex search\n",
    "3. Perform the evaluation and display the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c03f03d-1263-47bd-9208-096641c884df",
   "metadata": {
    "collapsed": false,
    "name": "Eval_Overview"
   },
   "source": "Typically, a framework such as [ragas](https://docs.ragas.io/en/stable/) would be used to perform the evaluation, but in order to keep the lab setup minimal, we are going to do the eval without the help of an external library.\n\n## Eval Metrics\nOur first eval set is going to be searching for a single specific chunk. Below is a set of search queries with the chunk we would expect to get back. Given this focused search effort, we'll use the following metrics for evaluation:\n\n- Hit@1 - determines if our search brought back the expected result as the first item retrieved\n- Hit@3 - measures if our expected chunk was present in the top 3 results\n- Mean Reciprocal Rank (MRR) - this metric is focused on how quickly the retrieval can find the first relevant result. Ex: if our expected chunk is at rank 1, then the reciprocal rank is 1. If our expected chunk is third, then the reciprocal rank is 1/3.\n- Miss rate - the rate at which the retrieval did not return our expected chunk at all.\n- P50/90/99 latency - this measures the speed of the retrieval results. P50 = indicates that 50% of the requests were returned in this time or less."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d196d1-b06d-4031-a876-3fd0cb692882",
   "metadata": {
    "language": "python",
    "name": "Create_Eval_Set"
   },
   "outputs": [],
   "source": "exact_eval_set = [\n    {\n        \"query\": \"When will the Ault Park trail plan complete?\",\n        \"expected_chunk\": \"AULT PARK VALLEY TRAIL One of the busiest trails in Cincinnati Parks is experiencing serious erosion issues along the creek also housing important sewer infrastructure. This project shores up the trail to keep hikers safe in advance of a larger MSD sewer project in the coming years to protect the trail in the long term. The project is underway and will close out in early 2025.\"\n    },\n    {\n        \"query\": \"When was the Sawyer Point Park playground burnt down?\",\n        \"expected_chunk\": \"SAWYER POINT PLAYGROUND AND PARK PLANNING Work is underway to restore the Sawyer Point Park playground, which was suddenly destroyed by a massive fire in November 2024. This project represents a chance to create an amazing new, uniquely Cincinnati, amenity for the next generation of park users of a wide range of ages and abilities to enjoy. The new playground will be built in the vicinity of the former playground though not in the same location. The goal is to engage with the community to develop something truly fantastic in this iconic regional park serving as a distinctive source of lasting pride for our city. The project also creates an opportunity to comprehensively review the layout of the park to guide a longer-term plan for improvements in the coming years.\"\n    },\n    {\n        \"query\": \"How many miles is the CROWN network?\",\n        \"expected_chunk\": \"BRAMBLE PARK TRAIL This project is a partnership with the community and will utilize a State of Ohio Department of Natural Resources grant. This will be the first segment of the Little Duck Creek Trail and run 0.35 miles in length through Bramble Park in Madisonville. The trail will connect to the Murray Trail, part of the CROWN network connecting more than 104 miles of trails in Cincinnati. Planning will take place during 2025.\"\n    },\n    {\n        \"query\": \"When did Smale park open?\",\n        \"expected_chunk\": \"SMALE CONCRETE & GRANITE UPGRADES This award-winning, heavily used signature Cincinnati Park opened in 2012. Sections of concrete and specialized granite need repair in order to maintain this regional asset.\"\n    },\n    {\n        \"query\": \"Which park was added to the National Register of Historic Places?\",\n        \"expected_chunk\": \"GIBSON HOUSE ROOF & FAÇADE This architecturally important structure was built in the middle 19th century and added to the National Register of Historic Places in 1976. Critical repairs are needed to preserve this treasure, which is now used for offices and a rental venue. Construction is planned to begin early 2026.\"\n    },\n    {\n        \"query\": \"Who is the Park Board partnering with for the Smale River's Edge project?\",\n        \"expected_chunk\": \"SMALE RIVER’S EDGE The U.S. Army Corps of Engineers and the Cincinnati Park Board are partnering on a study to improve and revitalize the Cincinnati Ohio River’s edge along the western edge of Smale Riverfront Park. The overall vision is to make the Cincinnati Riverfront a welcoming, safe, sustainable park, serving as a gateway to connect people to their heritage, community, and the natural environment for generations to come. The project will provide opportunities for ecosystem restoration and recreation, while protecting Cincinnati’s Riverfront from erosion. Initial design selection of this multi-million project will be complete in mid-2025 with construction planned to start in 2027.\"\n    },\n    {\n        \"query\": \"How long will the California Woods Hydrological plan take?\",\n        \"expected_chunk\": \"CALIFORNIA WOODS HYDROLOGICAL PLAN DESIGN This amazing preserve is experiencing significant erosion issues that threaten long-term public access to the park. A specialized firm has been selected to develop a plan for sustainable interventions to the stream flow to mitigate the on-going erosion issues in the most environmentally sustainable manner. Investigation and design work begins in the second quarter of 2025 and will take about a year to finalize.\"\n    },\n    {\n        \"query\": \"Which park plan is partering with the Cincinnati Off Road Alliance?\",\n        \"expected_chunk\": \"MT. AIRY BIKE SKILLS COURSE This partnership with the Cincinnati Parks Foundation and the Cincinnati Off Road Alliance (CORA) will nearly double the existing mileage of mountain biking trails within Mt. Airy Forest. It will be the first beginner natural surface trail experience within the city. With input from the community, the project has been funded and a contractor selected. The project is anticipated to be complete in early 2026.\"\n    },\n    {\n        \"query\": \"How many acres is the Cincinnati Park system comprised of?\",\n        \"expected_chunk\": \"CINCINNAT PARKS PARK IMPROVEMENT PROJECTS 3-YEAR PLAN Cincinnati Parks' 5,000 acres consist of 8 regional parks, 70 neighborhood parks, 34 preserves and natural areas, 5 parkways, 65 miles of hiking trails, 80,000 street trees on 1,000 miles of City streets, 6 nature centers, 18 scenic overlooks, 52 playgrounds, 500 landscaped gardens, and over 100 picnic areas. With all of this to care for, there are constant needs of all shapes and sizes. Whether it be a bad sidewalk, an aging playground, a leaking roof, or a park that could use a complete facelift, there’s plenty to do to keep our parks looking great and best serving our residents and users. This is why the Board of Park Commissioners approved a work plan, generated by Parks staff, outlining projects underway and planned over the next 3 years. This plan represents a roadmap of what Cincinnati Parks will be prioritizing in the coming years and creates transparency into improvement projects. This was developed after a careful evaluation based on a number of factors including safety, equity, efficiencies, long-term maintenance, available funding, and more. This plan represents current priorities, capacity, and needs, and is a living document that will be updated as circumstances evolve and schedules are adjusted.\"\n    },\n    {\n        \"query\": \"Which communities does the Burnet Woods dog park serve?\",\n        \"expected_chunk\": \"BURNET WOODS DOG PARK This new community dog park will serve Clifton, Corryville, CUF, and the surrounding areas, further contributing to the attractiveness and quality of life. The project represents a partnership with a number of community supporters, partners, and donors, including the Cincinnati Parks Foundation and Clifton Pop-up-Pup-Party (PUPP). The new amenity is expected to be under construction in May 2025 and take about 3 months to complete.\"\n    }\n    \n]"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b4707b-c54b-41f1-9541-4176eaa6e4b2",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "Eval_Setup"
   },
   "outputs": [],
   "source": "from snowflake.snowpark import Session\nfrom snowflake.snowpark.functions import col\nimport json\nimport re\n\nmodel = 'snowflake-arctic-embed-m-v1.5'\n\ndef escape_sql_string(s):\n    return s.replace(\"'\", \"''\")\n\ndef vector_search(query, k=3):\n    safe_query = escape_sql_string(query)\n    return session.sql(f\"\"\"\n        SELECT chunk, VECTOR_COSINE_SIMILARITY(\n            docs_chunks_table.embedding,\n            SNOWFLAKE.CORTEX.EMBED_TEXT_768('{model}', '{safe_query}')\n        ) AS similarity\n        FROM docs_chunks_table\n        ORDER BY similarity DESC\n        LIMIT {k}\n    \"\"\").collect()\n\ndef cortex_search(query, limit=3):\n    parks_search_service = (root.databases[\"RETRIEVAL_LAB\"]\n                                   .schemas[\"PUBLIC\"]\n                                   .cortex_search_services[\"parks_search_service\"])\n    resp = parks_search_service.search(\n        query=query,\n        columns=[\"chunk\"],\n        limit=limit\n    )\n    results = json.loads(resp.to_json())['results']\n    return results\n\n\ndef normalize(text):\n    # Lowercase, remove extra whitespace, and normalize newlines\n    return re.sub(r'\\s+', ' ', text.strip().lower())\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34b9f8e-d836-487d-b204-75f62a69e8cc",
   "metadata": {
    "language": "python",
    "name": "Define_Eval_Functions"
   },
   "outputs": [],
   "source": "import time\n\ndef run_exact_eval():\n    results = []\n\n    for item in exact_eval_set:\n        query = item['query']\n        expected = item['expected_chunk']\n\n        # Vector search with timing\n        start_time = time.time()\n        vector_results = vector_search(query, k=3)\n        vector_time = time.time() - start_time\n        vector_chunks = [r['CHUNK'] for r in vector_results]\n        vector_match_rank = next(\n            (i + 1 for i, chunk in enumerate(vector_chunks)\n             if normalize(chunk) == normalize(expected)),\n            None\n        )\n\n        # Cortex search with timing\n        start_time = time.time()\n        cortex_results = cortex_search(query, limit=3)\n        cortex_time = time.time() - start_time\n        cortex_chunks = [r['chunk'] for r in cortex_results]\n        cortex_match_rank = next(\n            (i + 1 for i, chunk in enumerate(cortex_chunks)\n             if normalize(chunk) == normalize(expected)),\n            None\n        )\n\n        results.append({\n            \"query\": query,\n            \"expected_chunk\": expected,\n            \"vector_hit_rank\": vector_match_rank or \"Miss\",\n            \"vector_chunks\": vector_chunks,\n            \"vector_time\": vector_time,\n            \"cortex_hit_rank\": cortex_match_rank or \"Miss\",\n            \"cortex_chunks\": cortex_chunks,\n            \"cortex_time\": cortex_time\n        })\n\n    return results\n\n\nimport numpy as np\n\ndef compute_metrics(results, method):\n    total = len(results)\n    hit_at_1 = 0\n    hit_at_3 = 0\n    reciprocal_ranks = []\n    ranks = []\n    misses = 0\n    times = []\n\n    for r in results:\n        hit_rank = r[f\"{method}_hit_rank\"]\n        response_time = r[f\"{method}_time\"]\n        times.append(response_time)\n\n        if isinstance(hit_rank, int):\n            if hit_rank == 1:\n                hit_at_1 += 1\n            if hit_rank <= 3:\n                hit_at_3 += 1\n            reciprocal_ranks.append(1.0 / hit_rank)\n            ranks.append(hit_rank)\n        else:\n            misses += 1\n            reciprocal_ranks.append(0.0)\n\n    accuracy = hit_at_1 / total\n    hit3 = hit_at_3 / total\n    mrr = sum(reciprocal_ranks) / total\n    mean_rank = sum(ranks) / len(ranks) if ranks else None\n    miss_rate = misses / total\n    avg_time = np.mean(times)\n\n    p50 = np.percentile(times, 50)\n    p90 = np.percentile(times, 90)\n    p99 = np.percentile(times, 99)\n\n    return {\n        \"Accuracy (Hit@1)\": round(accuracy, 3),\n        \"Hit@3\": round(hit3, 3),\n        \"MRR\": round(mrr, 3),\n        \"Miss Rate\": round(miss_rate, 3),\n        \"Avg Retrieval Time (ms)\": round(avg_time * 1000, 3),\n        \"P50 Latency (ms)\": round(p50 * 1000, 3),\n        \"P90 Latency (ms)\": round(p90 * 1000, 3),\n        \"P99 Latency (ms)\": round(p99 * 1000, 3)\n    }\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21487d7e-867c-48dd-8ab4-5109facbb828",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "Run_Eval"
   },
   "outputs": [],
   "source": "results = run_exact_eval()\n\nvector_metrics = compute_metrics(results, method=\"vector\")\ncortex_metrics = compute_metrics(results, method=\"cortex\")\n\ndf = pd.DataFrame({\n    \"Metric\": list(vector_metrics.keys()),\n    \"Vector Search\": list(vector_metrics.values()),\n    \"Cortex Search\": list(cortex_metrics.values())\n})\n\ndf"
  },
  {
   "cell_type": "markdown",
   "id": "15cb87f5-2404-402e-88fd-7d8755ca6e0e",
   "metadata": {
    "name": "Eval_2_Overview",
    "collapsed": false
   },
   "source": "### Another round of evals\nThe first set of eval questions was looking for exact matches. While that is one type of question we can expect, how about more open ended questions that will rely on multiple chunks? The following sample queries were chosen to minimize exact keyword matching and to evaluate how many relevant chunks were returned in the top 3 results.\n\nFor these questions, we will evaluate:\n- Precision@k - the ratio of relevant chunks retrieved to the total number of chunks retrieved\n- Recall@k - the ratio of relevant chunks retrieved to the total number of relevant chunks\n\n\nDetermining the value of `k` is an important consideration when evaluating retrieval performance. In our question set below, the first question has 7 relevant chunks, while the other two have only 3 each.\n\nIf we use `k=3`, then the maximum possible `recall@3` for the first question is limited to 3/7, even if the system retrieves the best results. On the other hand, if we use `k=7`, then the maximum possible `precision@7` for the second and third questions is only 3/7, since there are only 3 relevant chunks to be found.\n\nTo balance the tradeoff between precision and recall across questions of varying difficulty, we’ll evaluate performance at multiple values of `k: [3, 5, 7]`.\n"
  },
  {
   "cell_type": "code",
   "id": "7c07f316-c9d9-4bf5-8b52-d9702552f130",
   "metadata": {
    "language": "python",
    "name": "Create_Open_Eval_Set"
   },
   "outputs": [],
   "source": "open_eval_set = [\n    {\n        \"query\": \"Which parks will have new slides within the next year?\",\n        \"expected_chunks\": [\n            \"AULT PARK PLAYGROUND Parks is working with the Ault Park Advisory Council (APAC), who are fundraising to supplement State of Ohio grant funding on this new playground. With the help of the community, the project has been designed. It is anticipated work will begin in the fall of 2025 with completion before the end of the year.\",\n            \"SAWYER POINT PLAYGROUND AND PARK PLANNING Work is underway to restore the Sawyer Point Park playground, which was suddenly destroyed by a massive fire in November 2024. This project represents a chance to create an amazing new, uniquely Cincinnati, amenity for the next generation of park users of a wide range of ages and abilities to enjoy. The new playground will be built in the vicinity of the former playground though not in the same location. The goal is to engage with the community to develop something truly fantastic in this iconic regional park serving as a distinctive source of lasting pride for our city. The project also creates an opportunity to comprehensively review the layout of the park to guide a longer-term plan for improvements in the coming years.\",\n            \"GLENWAY PARK RENOVATIONS & PLAYGROUND Parks is working with the Cincinnati Parks Foundation and the surrounding community to renovate Glenway Park in East Price Hill. Fundraising and conceptual planning are in development and include a new playground, new lighting, regrading, and walking path improvements to increase accessibility and visibility. Construction is slated to begin mid-2026.\",\n            \"MCEVOY PARK IMPROVEMENTS This park renovation project looks to implement traffic calming measures, a new playground, pavilion renovations and some trail improvements. Planning will kick off late 2025 and is anticipated to last a year.\",\n            \"MT. AIRY MCFARLAN PLAYGROUND Parks is working on developing a new signature adventure playground in Mt. Airy Forest off of McFarlan. The playground project would correspond with retirement of the Area 3 playground near the disc golf course that is at the end of its lifecycle. Planning for this project is planned to kick off in 2026.\",       \n            \"HOFFNER PARK PLAYGROUND This playground is due for replacement. Work will begin in mid-2026.\"\n            \"MLK PARK RENOVATION Parks will work with the community to design a renovated park best serving the surrounding neighborhoods. Planning with the community for this project is expected to be completed in 2027.\"\n        ]\n    },\n        {\n        \"query\": \"Which bicycling paths have updates planned?\",\n        \"expected_chunks\": [\n            \"TED BERRY INTERNATIONAL FRIENDSHIP PARK RESTORATION This park has been in a state of disrepair due to an emergency fix to a major water main running through the park. This project returns the original state of the park and is a joint venture between the Cincinnati Park Board and Greater Cincinnati Water Works. Key project elements include restoring bike paths, walkways, seating walls, pavers, new trees, sod, shrubs, electrical, lighting, irrigation, and more. This magnificent park is slated to be fully restored in May 2025.\",\n            \"MT. AIRY BIKE SKILLS COURSE This partnership with the Cincinnati Parks Foundation and the Cincinnati Off Road Alliance (CORA) will nearly double the existing mileage of mountain biking trails within Mt. Airy Forest. It will be the first beginner natural surface trail experience within the city. With input from the community, the project has been funded and a contractor selected. The project is anticipated to be complete in early 2026.\",\n            \"OHIO RIVER WAY BIKE TRAIL EXTENSION THROUGH SAWYER POINT & YEATMAN’S COVE This partnership with Great Parks, the City of Cincinnati, and Metro will design and construct a 4.75-mile shared use trail. It will go from Sawyer Point on the Cincinnati riverfront east to the Lunken Trail and the 78-mile Little Miami Scenic Trail. Planning is underway in 2025.\"\n        ]\n        \n    },\n    {\n        \"query\": \"What updates are planned for Smale Park?\",\n        \"expected_chunks\": [\n            \"SMALE LOT 23 ENHANCEMENTS This project is a funding partnership with the Cincinnati Parks Foundation and has been in the works for several years. It includes adding large garden planters, granite promenade seat walls, a sandstone and granite donor wall and cladding walls. Construction will begin in late 2025 with completion in 2026.\",\n            \"SMALE RIVER’S EDGE The U.S. Army Corps of Engineers and the Cincinnati Park Board are partnering on a study to improve and revitalize the Cincinnati Ohio River’s edge along the western edge of Smale Riverfront Park. The overall vision is to make the Cincinnati Riverfront a welcoming, safe, sustainable park, serving as a gateway to connect people to their heritage, community, and the natural environment for generations to come. The project will provide opportunities for ecosystem restoration and recreation, while protecting Cincinnati’s Riverfront from erosion. Initial design selection of this multi-million project will be complete in mid-2025 with construction planned to start in 2027.\",\n            \"SMALE CONCRETE & GRANITE UPGRADES This award-winning, heavily used signature Cincinnati Park opened in 2012. Sections of concrete and specialized granite need repair in order to maintain this regional asset.\",\n        ]\n    }\n\n]\n\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "464c662f-d92b-403c-bfdf-62ecca7fd608",
   "metadata": {
    "language": "python",
    "name": "Define_Open_Eval_metrics",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def precision_at_k(retrieved, relevant, k):\n    retrieved_k = retrieved[:k]\n    hits = sum(normalize(r) in [normalize(chunk) for chunk in relevant] for r in retrieved_k)\n    return hits / k\n\ndef recall_at_k(retrieved, relevant, k):\n    retrieved_k = retrieved[:k]\n    hits = sum(normalize(r) in [normalize(chunk) for chunk in relevant] for r in retrieved_k)\n    return hits / len(relevant) if relevant else 0\n\n\ndef run_open_eval(k):\n    results = []\n\n    for item in open_eval_set:\n        query = item['query']\n        relevant_chunks = item['expected_chunks']\n\n        # Vector search\n        start_time = time.time()\n        vector_results = vector_search(query, k=k)\n        vector_time = time.time() - start_time\n        vector_chunks = [r['CHUNK'] for r in vector_results]\n\n        # Cortex search\n        start_time = time.time()\n        cortex_results = cortex_search(query, limit=k)\n        cortex_time = time.time() - start_time\n        cortex_chunks = [r['chunk'] for r in cortex_results]\n\n        results.append({\n            \"query\": query,\n            \"relevant_chunks\": relevant_chunks,\n            \"vector_chunks\": vector_chunks,\n            \"vector_time\": vector_time,\n            \"cortex_chunks\": cortex_chunks,\n            \"cortex_time\": cortex_time\n        })\n\n    return results\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "df1d6ce0-7970-494f-89ea-98fdd15cf586",
   "metadata": {
    "language": "python",
    "name": "Compute_Open_Eval_Metrics",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "def compute_open_metrics(results, method, k=3):\n    precisions = []\n    recalls = []\n    times = []\n\n    for r in results:\n        relevant = r[\"relevant_chunks\"]\n        retrieved = r[f\"{method}_chunks\"]\n        response_time = r[f\"{method}_time\"]\n        times.append(response_time)\n\n        p = precision_at_k(retrieved, relevant, k)\n        rcl = recall_at_k(retrieved, relevant, k)\n\n        precisions.append(p)\n        recalls.append(rcl)\n\n    avg_p = np.mean(precisions)\n    avg_r = np.mean(recalls)\n    avg_time = np.mean(times)\n\n    p50 = np.percentile(times, 50)\n    p90 = np.percentile(times, 90)\n    p99 = np.percentile(times, 99)\n\n    return {\n        f\"Avg Precision@{k}\": round(avg_p, 3),\n        f\"Avg Recall@{k}\": round(avg_r, 3),\n        \"Avg Retrieval Time (ms)\": round(avg_time * 1000, 3),\n        \"P50 Latency (ms)\": round(p50 * 1000, 3),\n        \"P90 Latency (ms)\": round(p90 * 1000, 3),\n        \"P99 Latency (ms)\": round(p99 * 1000, 3)\n    }\n",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "b9f90ccc-3ae4-42a8-8588-f7c16c95e791",
   "metadata": {
    "language": "python",
    "name": "Run_Open_Eval",
    "codeCollapsed": false
   },
   "outputs": [],
   "source": "import pandas as pd\n\nks = [3, 5, 7]\nmethods = [\"vector\", \"cortex\"]\n\nrows = []\n\nfor k in ks:\n    open_results_k = run_open_eval(k=k)  # Run retrieval at this k\n    for method in methods:\n        metrics = compute_open_metrics(open_results_k, method=method, k=k)\n        for metric_name, value in metrics.items():\n            rows.append({\n                \"k\": k,\n                \"Method\": method.capitalize(),\n                \"Metric\": metric_name,\n                \"Value\": value\n            })\n\n# Create the DataFrame\ndf_open = pd.DataFrame(rows)\n\n# Optional: Pivot for better readability\ndf_pivot = df_open.pivot(index=[\"Metric\", \"k\"], columns=\"Method\", values=\"Value\").reset_index()\n\ndf_pivot\n",
   "execution_count": null
  }
 ]
}